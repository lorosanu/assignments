{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discharging patients from the Intensive Care Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "At the Intensive Care Unit, patients who are in critical, life-threatening conditions receive continuous care. The purpose of the ICU recording is to bring the patient to a stable condition, after which they can go back to the normal ward. The moment of discharge is important: discharging a patient too early can lead to complications and being readmitted to the ICU with an increased risk of death. Keeping patients too long is also undesirable, capacity is limited and patients can get complications as a result of being at the ICU for too long. \n",
    "\n",
    "Use machine learning to help IC doctors decide when a patient can be discharged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Enormous amounts of data are continuously collected at the IC. Physiological values such as heart rate and blood pressure are recorded per minute, and, in addition, patient characteristics, clinical observations and laboratory results such as blood values are known.\n",
    "\n",
    "Here are the details of 3 (artificial) datasets with IC data:\n",
    "* age.csv\n",
    "    * file containing the patients age\n",
    "    * fields: *pat_id*, *age*\n",
    "* admission.csv\n",
    "    * file containing information on when a patient is admitted to and discharged from the IC\n",
    "    * fields: *pat_id*, *date_admission*, *date_discharge*\n",
    "* signal.csv\n",
    "    * file containing (artificial) information on 3 physiological parameters on the patient\n",
    "    * fields: *pat_id*, *day*, *hour*, *parameter*, *value*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Build an algorithm that can help the doctors at the IC decide who can be discharged using the signal data of the patient. The algorithm should be able to predict which patients have a high risk of being readmitted if they were to be discharged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data from csv file\n",
    "def load_data(input_file, sep=';', fields=None):\n",
    "    \"\"\"Load patient data from csv file\"\"\"\n",
    "    return pd.read_csv(input_file, header=0, sep=sep, usecols=fields)\n",
    "\n",
    "# functions for time handling\n",
    "def convert_time_in(s):\n",
    "    \"\"\"From string to datetime (start of day)\"\"\"\n",
    "    s += \" 00:00:00\"\n",
    "    return datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def convert_time_out(s):\n",
    "    \"\"\"From string to datetime (end of day)\"\"\"\n",
    "    s += \" 23:59:59\"\n",
    "    return datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def convert_time_mid(s):\n",
    "    \"\"\"From string to datetime (given hour)\"\"\"\n",
    "    return datetime.strptime(s, \"%Y-%m-%d %H\")\n",
    "\n",
    "# set up file names\n",
    "age_file = '/src/data/age.csv'\n",
    "adm_file = '/src/data/admission.csv'\n",
    "sig_file = '/src/data/signal.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and inspect the 'age' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_table = load_data(age_file, fields=['pat_id', 'age'])\n",
    "# set age field as integer\n",
    "age_table['age'] = pd.to_numeric(age_table['age'], downcast='integer')\n",
    "\n",
    "age_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and inspect the 'admission' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_table = load_data(\n",
    "    adm_file, \n",
    "    fields=['pat_id', 'date_admission', 'date_discharge'])\n",
    "\n",
    "# convert admission date to datetime format (start of day; hour=00:00)\n",
    "admission_table['date_admission'] = admission_table['date_admission'].map(convert_time_in)\n",
    "\n",
    "# convert discharge date to datetime format (end of day; hour=23:59)\n",
    "admission_table['date_discharge'] = admission_table['date_discharge'].map(convert_time_out)\n",
    "\n",
    "admission_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and inspect the 'signal' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_table = load_data(\n",
    "    sig_file, \n",
    "    fields=['pat_id', 'day', 'hour', 'parameter', 'value'])\n",
    "\n",
    "# combine day and hour columns\n",
    "signal_table['date_recording'] = signal_table['day'] + \" \" + signal_table['hour'].map(str)\n",
    "signal_table['date_recording'] = signal_table['date_recording'].map(convert_time_mid)\n",
    "\n",
    "# remove day and hour columns\n",
    "signal_table = signal_table.drop(\"day\", axis=1)\n",
    "signal_table = signal_table.drop(\"hour\", axis=1)\n",
    "\n",
    "signal_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the amount of information in each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age table contains {} entries\".format(len(age_table)))\n",
    "print(\"Admission table contains {} entries\".format(len(admission_table)))\n",
    "print(\"Signal table contains {} entries\".format(len(signal_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the patient ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ids(a, b):\n",
    "    \"\"\"Compare the ids in two series\"\"\"\n",
    "    \n",
    "    m = 0\n",
    "    s = set()\n",
    "    for pid in a:\n",
    "        if pid in b:\n",
    "            m += 1\n",
    "        else:\n",
    "            s.add(pid)\n",
    "    return m, sorted(list(s))\n",
    "\n",
    "age_ids = age_table.pat_id.unique()\n",
    "adm_ids = admission_table.pat_id.unique()\n",
    "sig_ids = signal_table.pat_id.unique()\n",
    "\n",
    "m1, s1 = compare_ids(age_ids, adm_ids)\n",
    "_, s2 = compare_ids(adm_ids, age_ids)\n",
    "print(\"Age and admission tables have {} common patients\".format(m1))\n",
    "print(\"\\t- the {} patients without admissions are: {}\". format(len(s1), s1))\n",
    "print(\"\\t- the {} admitted patients without known age are: {}\". format(len(s2), s2))\n",
    "\n",
    "m1, s1 = compare_ids(age_ids, sig_ids)\n",
    "_, s2 = compare_ids(sig_ids, age_ids)\n",
    "print(\"\\nAge and signal tables have {} common patients\".format(m1))\n",
    "print(\"\\t - the {} patients without recorded signals are: {}\". format(len(s1), s1))\n",
    "print(\"\\t - the {} recorded patients without known age are: {}\". format(len(s2), s2))\n",
    "\n",
    "m1, s1 = compare_ids(adm_ids, sig_ids)\n",
    "_, s2 = compare_ids(sig_ids, adm_ids)\n",
    "print(\"\\nAdmission and signal tables have {} common patients\".format(m1))\n",
    "print(\"\\t- the {} admitted patients without recorded signals are: {}\". format(len(s1), s1))\n",
    "print(\"\\t- the {} recorded patients without known admissions are: {}\". format(len(s2), s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the entries that have common ids in all 3 tables\n",
    "ids = set()\n",
    "for pid in age_ids:\n",
    "    if pid in adm_ids and pid in sig_ids:\n",
    "        ids.add(pid)\n",
    "\n",
    "age_table = age_table[age_table.pat_id.isin(ids)]\n",
    "admission_table = admission_table[admission_table.pat_id.isin(ids)]\n",
    "signal_table = signal_table[signal_table.pat_id.isin(ids)]\n",
    "\n",
    "print(\"Age table contains {} entries\".format(len(age_table)))\n",
    "print(\"Admission table contains {} entries\".format(len(admission_table)))\n",
    "print(\"Signal table contains {} entries\".format(len(signal_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the number of re-admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_re_admissions():\n",
    "    \"\"\"Detect re-admissions of patients in the admission table\"\"\"   \n",
    "    \n",
    "    duplicates = admission_table.groupby('pat_id').pat_id.count()\n",
    "    duplicates = Counter(duplicates.tolist())\n",
    "    return duplicates\n",
    "\n",
    "counts = detect_re_admissions()\n",
    "for n_adm, n_pat in counts.items():\n",
    "    print(\"{:4} patient(s) have {} logged admission(s)\".format(\n",
    "        int(n_pat), n_adm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inspect the signal recordings on each admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(pid, age, admissions, signals):\n",
    "    \"\"\"Pretty print the patient's information\"\"\"\n",
    "    \n",
    "    print('Patient data')\n",
    "    print(\"  * id:  {}\".format(pid))\n",
    "    print(\"  * age: {}\".format(age))\n",
    "    \n",
    "    print(\"  * history of admissions\")\n",
    "    for date_in, date_out in admissions:\n",
    "        print(\"    - from {} to {}\".format(date_in, date_out))\n",
    "            \n",
    "    for i in range(len(signals)):\n",
    "        print(\"  * signal recordings for admission #{}\".format(i+1))\n",
    "        for signal_type, recordings in signals[i].items():\n",
    "            rounded = [round(x, 2) for x in recordings[-10:]]\n",
    "            print(\"    - {}: (...) {}\".format(signal_type, rounded)) \n",
    "    \n",
    "def inspect_patient(pid):\n",
    "    \"\"\"Inspect available data on a given patient id\"\"\"\n",
    "    \n",
    "    # get the patient's age\n",
    "    age = age_table[age_table.pat_id == pid].age.item()\n",
    "    \n",
    "    # get the patient's admission dates    \n",
    "    admissions = []\n",
    "    selection = admission_table[admission_table.pat_id == pid]\n",
    "    for row in selection.itertuples():\n",
    "        admissions.append((row.date_admission, row.date_discharge))\n",
    "\n",
    "    # get the patient's signals for each admission\n",
    "    signal_types = signal_table.parameter.unique()\n",
    "    signals = []\n",
    "    for date_in, date_out in admissions:\n",
    "        match = {}\n",
    "        for signal in signal_types:\n",
    "            match[signal] = []\n",
    "            selection = signal_table.query(\n",
    "                \"(pat_id == @pid) & \"\\\n",
    "                \"(parameter == @signal) & \"\\\n",
    "                \"(@date_in <= date_recording <= @date_out)\")\n",
    "            for row in selection.itertuples():\n",
    "                match[signal].append(row.value)\n",
    "        signals.append(match)\n",
    "    \n",
    "    return age, admissions, signals\n",
    "\n",
    "pid = 470\n",
    "age, admissions, signals = inspect_patient(pid)\n",
    "display_data(pid, age, admissions, signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show mean values for blood_pressure, respiration rate and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_signal(signal_type):\n",
    "    \"\"\"Get the average value of the recorded signal type\"\"\"\n",
    "    selection = signal_table[signal_table.parameter == signal_type].value\n",
    "    return np.mean(selection)\n",
    "    \n",
    "signal_means={\n",
    "    'blood_pressure': get_average_signal('blood_pressure'),\n",
    "    'respiration_rate': get_average_signal('respiration_rate'),\n",
    "    'temperature': get_average_signal('temperature'),\n",
    "}\n",
    "\n",
    "print(signal_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "* pre-processing\n",
    "    * on the *age* table\n",
    "        * set age field as integer value\n",
    "    * on the *admission* table\n",
    "        * convert *date_admission* field to datetime format (replace missing hour with 00:00 to consider a full day)\n",
    "        * convert *date_discharge* field to datetime format (replace missing hour with 23:59 to consider a full day)\n",
    "        * add a new boolean column *high\\_risk* based on the event of a succedding quick readmission\n",
    "    * on the *signal* table\n",
    "        * merge the *day* and *hour* columns under a single column and convert it to a datetime format\n",
    "    * on all tables\n",
    "        * keep only the entries of the 1425 common patients\n",
    "        \n",
    "* merge data sources and generate **features for classification**\n",
    "    * target output variable *y*\n",
    "        * the *high_risk* field denoting a patient's iminent re-admission to the ICU\n",
    "        * for the moment, consider as high risk a patient being re-admitted to the ICU under a week of previous discharge\n",
    "        * there are 64 patients with more than one admission to the ICU in the dataset\n",
    "        * only 29 out of the 64 admissions validate the one-week condition\n",
    "    * explanatory input variables *x* (20 features)\n",
    "        * age\n",
    "        * time spent in the ICU (number of days)\n",
    "        * statistics computed on the recordings of blood pressure, respiration rate and temperature (on each patient's admission to the ICU)\n",
    "            * difference between last value and first value\n",
    "            * difference between maximum value and minimum value\n",
    "            * difference between the maximum values of the second half and first half\n",
    "            * difference between the minimum values of the second half and first half\n",
    "            * difference between the mean values of the second half and first half\n",
    "            * difference between the standard deviation values of the second half and first half\n",
    "    * admissions with missing signals for blood pressure, respiration rate or temperature each generate zero-valued features\n",
    "    * complete list of features (normalized)\n",
    "        * *age*\n",
    "        * *period*\n",
    "        * *blood_pressure_difference_last_first*\n",
    "        * *blood_pressure_difference_max_min*\n",
    "        * *blood_pressure_difference_max2_max1*\n",
    "        * *blood_pressure_difference_min2_min1*\n",
    "        * *blood_pressure_difference_mean2_mean1*\n",
    "        * *blood_pressure_differnece_std2_std1*\n",
    "        * *respiration_rate_difference_last_first*\n",
    "        * *respiration_rate_difference_max_min*\n",
    "        * *respiration_rate_difference_max2_max1*\n",
    "        * *respiration_rate_difference_min2_min1*\n",
    "        * *respiration_rate_difference_mean2_mean1*\n",
    "        * *respiration_rate_difference_std2_std1*\n",
    "        * *temperature_difference_last_first*\n",
    "        * *temperature_difference_max_min*\n",
    "        * *temperature_difference_max2_max1*\n",
    "        * *temperature_difference_min2_min1*\n",
    "        * *temperature_difference_mean2_mean1*\n",
    "        * *temperature_difference_std2_std1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features on the signal sequence\n",
    "def extract_features(data):\n",
    "    \"\"\"\n",
    "    Define the features that describe the signal sequence\n",
    "        - difference between last value and first value\n",
    "        - difference between maximum value and minimum value\n",
    "        - difference between the maximum values of the 2nd half and 1st half\n",
    "        - difference between the minimum values of the 2nd half and 1st half\n",
    "        - difference between the mean values of the 2nd half and 1st half\n",
    "        - difference between the standard deviation values of the 2nd half and 1st half\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(data) >= 2:\n",
    "        # split data into first and second halves\n",
    "        middle = len(data) // 2 \n",
    "        first_half = data[:middle]\n",
    "        second_half = data[middle:]\n",
    "        \n",
    "        return [\n",
    "            data[-1] - data[0],\n",
    "            np.max(data) - np.min(data),\n",
    "            np.max(second_half) - np.max(first_half),\n",
    "            np.min(second_half) - np.min(first_half),\n",
    "            np.mean(second_half) - np.mean(first_half),\n",
    "            np.std(second_half) - np.std(first_half)\n",
    "        ]\n",
    "    \n",
    "    # consider a sequence of average values\n",
    "    # => zero-valued differences\n",
    "    \n",
    "    mean_signal = [0.0 for _ in range(6)]    \n",
    "    return mean_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input-target variables\n",
    "def generate_dataset(n_days=7, n_feat=20):\n",
    "    \"\"\"Create a new dataset for the classification process\"\"\"\n",
    "    \n",
    "    # initialize the features list and the label list\n",
    "    x = []\n",
    "    y = []\n",
    "        \n",
    "    # extract the list of unique signal types\n",
    "    signal_types = sorted(signal_table.parameter.unique())\n",
    "        \n",
    "    # for each patient\n",
    "    for age_row in age_table.itertuples():\n",
    "        # extract id and age\n",
    "        pid = age_row.pat_id\n",
    "        age = age_row.age\n",
    "\n",
    "        # extract ICU admissions and sort them by admission date\n",
    "        adm_selection = admission_table[admission_table.pat_id == pid]\n",
    "        adm_selection = adm_selection.sort_values('date_admission')\n",
    "\n",
    "        admissions = []\n",
    "        for adm_row in adm_selection.itertuples():\n",
    "            admissions.append((adm_row.date_admission, adm_row.date_discharge))\n",
    "\n",
    "        # check for high risks\n",
    "        for i in range(len(admissions)):  \n",
    "            date_in = admissions[i][0]\n",
    "            date_out = admissions[i][1]\n",
    "\n",
    "            # the number of days spent in ICU\n",
    "            period = (date_out - date_in).days\n",
    "\n",
    "            # check the high risk of the current admission  \n",
    "            high_risk = 0\n",
    "            if i < len(admissions) - 1:\n",
    "                next_date_in = admissions[i + 1][0]\n",
    "                # if the period between two admissions is under one week\n",
    "                if (next_date_in - date_in).days <= n_days:\n",
    "                    high_risk = 1\n",
    "\n",
    "            feat = [age, period]\n",
    "\n",
    "            # get the patient's signals for current admission\n",
    "            for signal in signal_types:\n",
    "                sig_selection = signal_table.query(\n",
    "                    \"(pat_id == @pid) & \"\\\n",
    "                    \"(parameter == @signal) & \"\\\n",
    "                    \"(@date_in <= date_recording <= @date_out)\")\n",
    "                \n",
    "                values = []\n",
    "                for row in sig_selection.itertuples():\n",
    "                    values.append(row.value)\n",
    "                    \n",
    "                feat.extend(extract_features(values))\n",
    "\n",
    "            # add features and label to dataset\n",
    "            if len(feat) == n_feat:\n",
    "                x.append(feat)\n",
    "                y.append(high_risk)\n",
    "\n",
    "    return x, y\n",
    "        \n",
    "x, y = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info on generated data\n",
    "n = len(x)\n",
    "npoz = sum(y)\n",
    "nneg = len(y) - npoz\n",
    "\n",
    "print(\n",
    "    \"Generated a dataset of {} entries, \"\\\n",
    "    \"with {} positive entries \"\\\n",
    "    \"and {} negative entries\".format(\n",
    "        n, npoz, nneg))\n",
    "\n",
    "# choose a random entry\n",
    "rand_index = random.randint(0, n - 1)\n",
    "sample_feat = x[rand_index]\n",
    "sample_label = y[rand_index]\n",
    "print(\"\\nExample of entry:\\n\\t- y = {}\\n\\t- x = {}\".format(\n",
    "    sample_label, sample_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split data into train (75%) and test (25%) subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in index of positive and negative samples\n",
    "pos_index = [i for i in range(len(y)) if y[i]]\n",
    "neg_index = [i for i in range(len(y)) if not y[i]]\n",
    "\n",
    "train_split = 0.75\n",
    "pos_index_75 = random.sample(pos_index, int(train_split * len(pos_index)))\n",
    "\n",
    "# define the indexes for train data: 75% of data\n",
    "train_index = pos_index_75.copy()\n",
    "train_index.extend(random.sample(neg_index, int(train_split * len(neg_index))))\n",
    "\n",
    "# handle the unbalanced training data set\n",
    "# - over-sample the minority class\n",
    "ndup = int(train_split * (nneg - npoz))\n",
    "for _ in range(ndup):\n",
    "    train_index.append(random.choice(pos_index_75))\n",
    "\n",
    "# define the indexes for test data: remaining data\n",
    "test_index = [i for i in pos_index if i not in train_index]\n",
    "test_index.extend(i for i in neg_index if i not in train_index)\n",
    "\n",
    "# final shuffle of positive-negative indexes\n",
    "random.shuffle(train_index)\n",
    "random.shuffle(test_index)\n",
    "\n",
    "# get the samples for training and testing\n",
    "train_x = [x[i] for i in train_index]\n",
    "train_y = [y[i] for i in train_index]\n",
    "\n",
    "test_x = [x[i] for i in test_index]\n",
    "test_y = [y[i] for i in test_index]\n",
    "\n",
    "print(\"Generated a train set of {} instances ({} positive)\".format(\n",
    "    len(train_x), sum(train_y)))\n",
    "print(\"Generated a test set of {} instances ({} positive)\".format(\n",
    "    len(test_x), sum(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize features to unit norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the normalizer on train data\n",
    "transformer = Normalizer().fit(train_x)\n",
    "\n",
    "# apply the normalizer on train data\n",
    "train_x = transformer.transform(train_x)\n",
    "\n",
    "# apply the normalizer on test data\n",
    "test_x  = transformer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example of normalized entry: {}\".format(\n",
    "    transformer.transform([sample_feat])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification problem solved with a Neural Network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a NeuralNetwork classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 128),\n",
    "    learning_rate_init=0.001,\n",
    "    alpha=0.01,\n",
    "    max_iter=100,\n",
    "    batch_size=252,\n",
    "    verbose=1)\n",
    "\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the classification performance\n",
    "    * accuracy\n",
    "    * confusion matrix\n",
    "    * precision & recall\n",
    "    * ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc):\n",
    "    \"\"\"Draw ROC curve\"\"\"\n",
    "    \n",
    "    plt.plot(\n",
    "        fpr, \n",
    "        tpr,\n",
    "        color='red',\n",
    "        label=\"ROC curve (area = {:.2%}\".format(roc_auc))    \n",
    "    plt.plot([0, 1], [0, 1], color='blue', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_performance(real, predicted):\n",
    "    \"\"\"Display performance metrics\"\"\"\n",
    "    \n",
    "    acc = metrics.accuracy_score(real, predicted)\n",
    "    cm = metrics.confusion_matrix(real, predicted, labels=[1, 0])\n",
    "    report = metrics.classification_report(real, predicted)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(real, predicted)\n",
    "    auc = metrics.roc_auc_score(real, predicted)\n",
    "    \n",
    "    print(\"Accuracy:\\n{:.2%}\\n\".format(acc))\n",
    "    print(\"ConfusionMatrix:\\n{}\\n\".format(cm))\n",
    "    print(\"Report:\\n{}\\n\".format(report))\n",
    "    print(\"AUC:\\n{:.2%}\".format(auc))\n",
    "    \n",
    "    plot_roc(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels on TRAIN data\n",
    "predicted = model.predict(train_x)\n",
    "display_performance(train_y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check generalization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels on TEST data\n",
    "predicted = model.predict(test_x)\n",
    "display_performance(test_y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* bad performance (only a 54% AUC)\n",
    "* expect better results with more data (especially with more positive examples)\n",
    "* better domain knowledge could help investigate other features / approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspectives\n",
    "\n",
    "* try the approach on a bigger dataset\n",
    "* try other features\n",
    "* try feature selection\n",
    "* try other solution for handling missing values\n",
    "* try other solution for handling an imbalanced dataset\n",
    "* try other classification algorithms\n",
    "* tune hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
